{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Angus_Issues\\\\NorthCarolina_CameroonChapter_AngusIssues\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Angus_Issues\\\\NorthCarolina_CameroonChapter_AngusIssues'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "    def train_test_spliting(self):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        data['Date'] = pd.to_datetime(data['Date']) # Convert 'Date' column to datetime format\n",
    "        data = data.set_index('Date')\n",
    "\n",
    "        # Initialize forecast results DataFrame\n",
    "        forecast_results = pd.DataFrame(columns=['Date', 'Cow', 'Predicted Body Weight (kg)'])\n",
    "\n",
    "        # Define the date to split the data (adjust the date as needed)\n",
    "        split_date = pd.to_datetime('2022-02-15')\n",
    "\n",
    "        # Extract unique cow IDs from the DataFrame\n",
    "        unique_cows = data['Cow'].unique()\n",
    "\n",
    "        # Continue with the forecasting logic\n",
    "        for cow in unique_cows:\n",
    "            cow_data = data[data['Cow'] == cow]\n",
    "\n",
    "            # Ensure that the index is a DatetimeIndex\n",
    "            cow_data.index = pd.to_datetime(cow_data.index)\n",
    "\n",
    "            # Split the data into train and test based on the split_date\n",
    "            cow_train_data = cow_data[cow_data.index < split_date]\n",
    "            cow_test_data = cow_data[cow_data.index >= split_date]\n",
    "\n",
    "            # Fit the model and make predictions\n",
    "            #model_ETS = ETSModel(cow_train_data['Body Weight (kg)'], error='add', trend=None, seasonal=None)\n",
    "            model_ETS = ETSModel(cow_train_data['Body Weight (kg)'], order=self.config.order)\n",
    "            model_fit = model_ETS.fit()\n",
    "\n",
    "            # Make predictions for the test set\n",
    "            cow_predictions = model_fit.predict(start=len(cow_train_data), end=len(cow_train_data) + len(cow_test_data) - 1)\n",
    "\n",
    "            # Store the predictions\n",
    "            cow_forecast_df = pd.DataFrame({\n",
    "                'Date': cow_test_data.index,\n",
    "                'Cow': cow,\n",
    "                'Predicted Body Weight (kg)': cow_predictions\n",
    "            })\n",
    "\n",
    "            forecast_results = pd.concat([forecast_results, cow_forecast_df])\n",
    "\n",
    "        forecast_results.reset_index(drop=True, inplace=True)\n",
    "        print(forecast_results)\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        model_dir = os.path.join(self.config.root_dir, 'model_trainer')\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "        joblib.dump(model_fit, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-17 19:58:36,742: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-08-17 19:58:36,747: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-17 19:58:36,750: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-08-17 19:58:36,752: INFO: common: created directory at: artifacts]\n",
      "[2024-08-17 19:58:36,754: INFO: common: created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataTransformationConfig' object has no attribute 'order'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     data_transformation\u001b[38;5;241m.\u001b[39mtrain_test_spliting()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     data_transformation_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_data_transformation_config()\n\u001b[0;32m      4\u001b[0m     data_transformation \u001b[38;5;241m=\u001b[39m DataTransformation(config\u001b[38;5;241m=\u001b[39mdata_transformation_config)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mdata_transformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_spliting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[9], line 41\u001b[0m, in \u001b[0;36mDataTransformation.train_test_spliting\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m cow_test_data \u001b[38;5;241m=\u001b[39m cow_data[cow_data\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m split_date]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Fit the model and make predictions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#model_ETS = ETSModel(cow_train_data['Body Weight (kg)'], error='add', trend=None, seasonal=None)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m model_ETS \u001b[38;5;241m=\u001b[39m ETSModel(cow_train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody Weight (kg)\u001b[39m\u001b[38;5;124m'\u001b[39m], order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m)\n\u001b[0;32m     42\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m model_ETS\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make predictions for the test set\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataTransformationConfig' object has no attribute 'order'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.train_test_spliting()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
